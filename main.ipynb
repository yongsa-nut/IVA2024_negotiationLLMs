{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install openai\n",
    "!pip install backoff\n",
    "!pip install anthropic\n",
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nutju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\nutju\\AppData\\Local\\Temp\\ipykernel_12592\\1362840229.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import os\n",
    "import openai\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "import backoff\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI's GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "## ChatGPT function call\n",
    "client_OpenAI = openai.OpenAI()\n",
    "CHATGPT = 'gpt-3.5-turbo'\n",
    "FURBO = 'gpt-4-0125-preview'\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.RateLimitError, max_time=6000)\n",
    "def chat_completions_with_backoff(**kwargs):\n",
    "    return client_OpenAI.chat.completions.create(**kwargs)\n",
    "\n",
    "def gptQuery(history = [], model=CHATGPT, temperature = 0, n=1, echo = False):\n",
    "  out = chat_completions_with_backoff(model=model,\n",
    "                                     messages=history,\n",
    "                                     temperature=temperature, max_tokens = 2048,\n",
    "                                     n=n)\n",
    "  if echo: \n",
    "     print(history)\n",
    "     print(out.choices[0].message.content.strip()) \n",
    "  if n == 1:\n",
    "     return out.choices[0].message.content.strip()\n",
    "  return [response.message.content.strip() for response in out.choices ]\n",
    "\n",
    "print(gptQuery([{\"role\":\"user\", \"content\":\"Hello Test\"}], model =CHATGPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anthropic's Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm Claude, an AI assistant created by Anthropic. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "## anthropic's function call\n",
    "client_anthropic = anthropic.Anthropic()\n",
    "OPUS = \"claude-3-opus-20240229\"\n",
    "SONNET = \"claude-3-sonnet-20240229\"\n",
    "\n",
    "# Claude's fommating: \n",
    "## [{\"role\":\"user\",\"content\":\"Hello\"}, {\"role\",\"assistant\",\"content\":\"Greeting\"}]\n",
    "# no n for claude -> only once.\n",
    "def claudeQuery(history = [], model=SONNET, temperature = 0, echo=False):\n",
    "    out = client_anthropic.messages.create(\n",
    "        model = model,\n",
    "        max_tokens=2048,\n",
    "        temperature=temperature,\n",
    "        system=\"\",\n",
    "        messages= history\n",
    "    )\n",
    "    if echo: \n",
    "        print(history)\n",
    "        print(out.content[0].text)\n",
    "    time.sleep(1)\n",
    "    return out.content[0].text\n",
    "\n",
    "print(claudeQuery([{\"role\":\"user\", \"content\":\"Hello Test\"}], model = SONNET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [CHATGPT, FURBO, SONNET, OPUS]\n",
    "\n",
    "## Helper function to call different models\n",
    "def query(history, model, **args):\n",
    "    if model == CHATGPT or model == FURBO:\n",
    "        return gptQuery(history = history, model = model, **args)\n",
    "    elif model == SONNET or model == OPUS:\n",
    "        return claudeQuery(history = history, model = model, **args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negotiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment's parameters\n",
    "\n",
    "seller_payoff = [50, 15, 30]\n",
    "buyer_payoff  = [10, 40, 25]\n",
    "accepted_threshold = 0.7 # must be greater than or equal threshold*max to accept\n",
    "\n",
    "display_rules = [\"happy-angry\",\"happy-sad\"]\n",
    "num_turns = [5, 10]\n",
    "prompt_modes = ['implicit','explicit']\n",
    "\n",
    "expressive_levels = [1.0, 0.25, 0.05] \n",
    "\n",
    "\n",
    "offer_inst = [\"first\",\"second\",\"third\",\"fourth\",\"fifth\",\"sixth\",\"seventh\",\"eighth\",\"nineth\",\"tenth\"]\n",
    "\n",
    "# split at the delimiter and grab the inside\n",
    "def parseResponse(response):\n",
    "    try:\n",
    "        return response.split(\"'''\")[1]\n",
    "    except:\n",
    "        return \"NA\"\n",
    "\n",
    "def calPayoff(offers, payoffs=[50,15,30], perspective='seller'):\n",
    "    if perspective == 'seller':\n",
    "        return sum([(9-offers[i])*payoffs[i] for i in range(len(offers))])\n",
    "    if perspective == 'buyer':\n",
    "        return sum([(offers[i]-1)*payoffs[i] for i in range(len(offers))])\n",
    "\n",
    "\n",
    "\n",
    "expressions = {\"neutral\": \"The buyer's face looks relaxed with no significant movements.\",\n",
    "               \"happy-low\": \"The corners of the buyer's lips are slightly upturned. There is a slight crinkle at the corner of the buyer's eyes and slightly raised cheeks.\",\n",
    "               \"happy-high\": \"The corners of the buyer's lips are clearly upturned and the teeth are visible through a parting of the lips.  There is a clear crinkle at the corner of the eyes and the cheeks are raised. There is a sparkle in the eyes.\",\n",
    "               \"sad-low\":\"The buyer's brows are slightly furrowed, and the corners of the buyer's lips are pulled down slightly.\",\n",
    "               \"sad-high\":\"The buyer's brows are furrowed, and the corners of the buyer's lips are pulled down while the lips are pursed. The buyer's eyes look down and are slightly wet. There's a crease in the forehead.\",\n",
    "               \"angry-low\":\"The buyer's eyes are slightly narrowed and the buyer's brows are furrowed, creating a small crease between them. The buyer's lips are pressed together and form a tight line. The nostrils flare briefly as there is an exhalation through the nose. There is an overall slight tensioning of the facial muscles particularly around the jaw.\",\n",
    "               \"angry-high\":\"The buyer's eyes are narrow and the brows are furrowed, creating a crease between them. The lips are pressed together and form a tight line. The buyer's nostrils flare briefly as there is an exhalation through the nose, followed by a wrinkling around the nose. The facial muscles tense particularly around the jaw. The gaze is fixed on you.\"}\n",
    "\n",
    "agent_responses = ['''\"I do not think this offer could work.\" The buyer responded. ''', \n",
    "                   '\"I think this offer could work.\" The buyer responded. ']\n",
    "\n",
    "def gen_expression(offer, thresholds, display_rule):\n",
    "    # thresholds = [min_utility, negative_mid, neutral_lower, neutral_upper, positive_mid, max_utility] \n",
    "    if thresholds[2] <= offer <= thresholds[3]:\n",
    "        return expressions[\"neutral\"] + \"\\n\"\n",
    "    elif thresholds[3] < offer <= thresholds[4]:\n",
    "        return expressions[\"happy-low\"] + \"\\n\"\n",
    "    elif thresholds[4] < offer <= thresholds[5]:\n",
    "        return expressions['happy-high'] + \"\\n\"\n",
    "    elif thresholds[1] <= offer < thresholds[2]:\n",
    "        return expressions[display_rule.split('-')[1]+\"-low\"] + \"\\n\"\n",
    "    else:\n",
    "        return expressions[display_rule.split('-')[1]+'-high'] + \"\\n\"\n",
    "\n",
    "def agentResponse(offers, buyer_payoff = buyer_payoff, threshold = 0.67, exp_level = 0.1, display_rule = \"happy-angry\", face_only=False):\n",
    "    # build a utility line\n",
    "    max_utility = calPayoff([9,9,9], buyer_payoff, 'buyer')\n",
    "    threshold_util = max_utility*threshold\n",
    "    neutral_upper = min(max_utility, threshold_util + (exp_level)*max_utility)\n",
    "    neutral_lower = max(0, threshold_util - (exp_level)*max_utility)\n",
    "    negative_mid  = (neutral_lower)/2\n",
    "    positive_mid  = (max_utility + neutral_upper)/2\n",
    "    expression_thresholds = [0, negative_mid, neutral_lower, neutral_upper, positive_mid, max_utility] \n",
    "    #print(expression_thresholds)\n",
    "\n",
    "    offer_util = calPayoff([int(n) for n in offers.split('-')], buyer_payoff, 'buyer') \n",
    "    # grab the response + the expression\n",
    "    if face_only:\n",
    "        return gen_expression(offer_util, expression_thresholds, display_rule)\n",
    "    \n",
    "    response = agent_responses[offer_util >= threshold_util] + gen_expression(offer_util, expression_thresholds, display_rule)\n",
    "    return response\n",
    "\n",
    "def genInstruction(turn=5):\n",
    "    opening = \"In this task, you will play the role of seller of a consignment of mobile phones. Your objective is to negotiate the price, the warranty period, and the duration of the phones' service contracts.\\n\"\n",
    "    payoff      = '''Each one of them has 9 levels that you can choose from, and you will get points as follows. \n",
    "For the price, level 9 = 0 points; level 8 = 50 points; level 7 = 100 points; level 6 = 150 points; level 5 = 200 points; level 4 = 250 points; level 3 = 300 points; level 2 = 350; and level 1 = 400 points (increments of 50 points per level). \n",
    "For the warranty period, level 9 = 0 pointslevel 8 = 15 points; level 7 = 30 points; level 6 = 45 points; level 5 = 60 points; level 4 = 75 points; level 3 = 90 points; level 2 = 105; and level 1 = 120 points (increments of 15 points per level). \n",
    "For the duration of the service contract, level 9 = 0 pointslevel 8 = 30 points; level 7 = 60 points; level 6 = 90 points; level 5 = 120 points; level 4 = 150 points; level 3 = 180 points; level 2 = 210; and level 1 = 240 points (increments of 30 points per level). \n",
    "Therefore, the best deal for you is 1-1-1 (price's level 1, warranty's level 1, and service duration's level 1), for a total outcome of 760 points (400 + 120 + 240). \n",
    "The association between levels and scores is your payoff table. The buyer has their own payoff table, which you do not know.\\n'''\n",
    "    interchange = f\"The interchange between the seller and the buyer will go as follows. The seller (you) will propose the offer, and then the buyer will respond to your offer. This negotiation will go on for {turn} turns. Afterward, you will propose your final offer, which the buyer may either accept or reject. If the buyer accepts, you will receive your points based on the payoff table above. If the buyer rejects, you will get nothing. Your objective is to earn as many points as possible.\"\n",
    "    return f\"{opening}{payoff}{interchange}\"\n",
    "\n",
    "def testOfferCalculation(model = CHATGPT, temperature = 0):\n",
    "    print(f\"Model = {model}\")\n",
    "    instruction = genInstruction() \n",
    "    for q in [\"Q: 9-9-9\",\"Q: 8-8-8\",\"Q: 7-6-5\",\"Q: 3-9-1\", \"Q: 4-2-3\"]:\n",
    "        question = '''To test your understanding of the task, please calculate your total points for the following offer.''' + q\n",
    "        hist = [{\"role\":\"user\",\"content\":instruction + \"\\n\" + question}]\n",
    "        response = query(hist,model, temperature=temperature)\n",
    "        print(response)\n",
    "    print(\"The correct answers are 0, 95, 265, 540, 535\")\n",
    "    return None\n",
    "\n",
    "def testOfferComparison(model = CHATGPT, temperature = 0):\n",
    "    print(f\"Model = {model}\")\n",
    "    instruction = genInstruction()\n",
    "    for q in [\"Q: a) 9-9-9 or b) 8-8-8\",\"Q: a) 3-2-1 or b) 1-2-3\",\"Q: a) 7-5-2 or b) 3-4-1\",\"Q: a) 7-9-1 or b) 8-3-2\",\"Q: a) 1-2-1 or b) 1-1-2\"]:\n",
    "        questions = '''To test your understand of the task, you will be presented with two offers. Please choose the offer (a or b) that is best for you.''' + q\n",
    "        hist = [{\"role\":\"user\",\"content\":instruction + \"\\n\" + questions}]\n",
    "        response = query(hist,model, temperature=temperature)\n",
    "        print(response)\n",
    "    print(\"The correct answers are b, b, b, b, a\")\n",
    "    return None\n",
    "\n",
    "def negotiation(model = CHATGPT, temperature = 0, turn = 5, prompt_mode = 'implicit',\n",
    "                buyer_payoff=buyer_payoff, accepted_threshold=0.67, exp_level = 0.0, display_rule = \"happy-angry\",\n",
    "                face_only = False):\n",
    "    # Building instruction\n",
    "    output_instruction = \"Please put your offer inside ''' ''' and use the following format: '''n-m-p''', where n is the level of the price, m is the level of the warranty period, and p is the level of the duration of the service contracts. For example, '''8-8-8''' means that your offer is the price at level 8, the warranty period at level 8, and the service contract duration is at level 8.\"\n",
    "    prompt_mode_inst = \"Only output the offer.\\n\"  if prompt_mode == \"implicit\" else \"Think about the seller first and then output the offer at the end.\\n\"\n",
    "\n",
    "    full_instruction = f\"{genInstruction(turn)} {output_instruction} {prompt_mode_inst}\"\n",
    "\n",
    "    # Ranking questions \n",
    "    ranking_q = \"Question: Please rank the buyer's score of price, warranty, and service duration from lower to high. Put the answer inside ''' ''', e.g., '''service < warranty < price''' \"\n",
    "\n",
    "    history = []\n",
    "    dat = {\"Model\": model, \"Temperature\": temperature, \"Turn\": turn, \"Prompt_mode\": prompt_mode, \"seller_payoff\":seller_payoff,\n",
    "           \"buyer_payoff\":buyer_payoff, \"accepted_threshold\": accepted_threshold, \"expressive_level\": exp_level, \n",
    "           \"display_rule\": display_rule, \"face_only\":face_only}\n",
    "\n",
    "    # Loop through number of interactions\n",
    "    for i in range(turn+1):\n",
    "        # build the turn \n",
    "        prompt = \"\"\n",
    "        if i == 0:\n",
    "            prompt = full_instruction + f\"Your {offer_inst[i]} offer: \"\n",
    "        elif i != turn:\n",
    "            #agent response\n",
    "            prompt = f\"{agent_response} Your {offer_inst[i]} offer: \"\n",
    "        else:\n",
    "            #ask before the final offer: \n",
    "            temp_history = history.copy()\n",
    "            temp_history.append({\"role\":\"user\",\"content\":agent_response + ranking_q})\n",
    "            ranking_response = parseResponse(query(temp_history, model, temperature = temperature))\n",
    "            \n",
    "            while ranking_response == \"NA\":\n",
    "                print(\"!!--REFUSE--!!\")\n",
    "                ranking_response = parseResponse(query(temp_history, model, temperature = temperature))\n",
    "\n",
    "            dat['ranking_response'] = ranking_response\n",
    "            \n",
    "            prompt = f\"{agent_response} Your final offer: \"\n",
    "\n",
    "        history.append({\"role\":\"user\",\"content\":prompt})\n",
    "        \n",
    "        # query \n",
    "        response = query(history, model, temperature=temperature)\n",
    "        while parseResponse(response) == \"NA\":\n",
    "            print(\"!!--NOT ANSWER --!!\")\n",
    "            response = query(history, model, temperature=temperature)\n",
    "\n",
    "        history.append({'role':'assistant','content':response})\n",
    "        dat['Turn = '+str(i+1)] = parseResponse(response)\n",
    "        agent_response = agentResponse(dat['Turn = '+str(i+1)], buyer_payoff, accepted_threshold, exp_level, display_rule, face_only)\n",
    "    \n",
    "    dat['Final_response'] = calPayoff([int(n) for n in dat['Turn = '+str(i+1)].split('-')]) if agent_response.startswith('\"I think') else \"reject\"\n",
    "\n",
    "    #for h in history: \n",
    "    #    print(h)\n",
    "    print(dat)\n",
    "\n",
    "    return dat\n",
    "\n",
    "def experiment(model, temperature, repeat=20):\n",
    "    dat = []\n",
    "\n",
    "    for dr in display_rules:\n",
    "        for exp_l in expressive_levels:\n",
    "            for face in [False, True]:\n",
    "                if exp_l == 1.0 and face:\n",
    "                    continue\n",
    "                for n in num_turns:\n",
    "                    for i in range(repeat):\n",
    "                        print(f\"{dr} {exp_l} {face} {n} {i}\")\n",
    "                        result = negotiation(model, temperature, n, exp_level=exp_l, display_rule=dr,\n",
    "                                             buyer_payoff=buyer_payoff, accepted_threshold=accepted_threshold,\n",
    "                                             face_only=face)\n",
    "                        result[\"i\"] = i\n",
    "                        dat.append(result)\n",
    "\n",
    "    return dat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the understanding of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    testOfferCalculation(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    testOfferComparison(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "1-9-4 550\n",
      "9-9-9\n",
      "[0, 15, 30, 30, 45, 45, 50, 60, 60, 60, 65, 75, 75, 75, 80, 80, 90, 90, 90, 95, 95, 100, 105, 105, 110, 110, 110, 115, 120, 120, 120, 125, 125, 125, 130, 130, 135, 135, 140, 140, 140, 145, 145, 150, 150, 150, 155, 155, 160, 160, 160, 165, 165, 170, 170, 175, 175, 180, 180, 180, 180, 185, 185, 190, 190, 190, 195, 195, 195, 200, 200, 200, 205, 205, 210, 210, 210, 210, 215, 215, 220, 220, 225, 225, 230, 230, 230, 235, 240, 240, 240, 245, 245, 245, 250, 250, 250, 255, 255, 260, 260, 260, 260, 265, 265, 270, 270, 275, 275, 280, 280, 280, 285, 290, 290, 290, 295, 295, 295, 300, 300, 300, 305, 305, 310, 310, 310, 310, 315, 315, 320, 320, 325, 325, 330, 330, 330, 335, 340, 340, 345, 345, 350, 350, 355, 360, 360, 360, 365, 365, 370, 370, 375, 375, 380, 380, 380, 385, 390, 390, 395, 395, 400, 400, 405, 410, 410, 415, 420, 425, 430, 430, 430, 435, 440, 440, 445, 445, 450, 455, 460, 460, 470, 475, 480, 485, 490, 490, 500, 505, 520, 550]\n"
     ]
    }
   ],
   "source": [
    "# Checking the best possible \n",
    "# [0, 195.0, 390.0, 450.0, 525.0, 600] (exp_level =0.1)\n",
    "# [0, 120.0, 240.0, 600, 600.0, 600] (exp_level =0.3)\n",
    "# [0, 0.0, 0, 600, 600.0, 600]    (exp_level =1.0)\n",
    "max_offer = \"9-9-9\"\n",
    "min_offer = \"1-1-1\"\n",
    "count = 0\n",
    "temp = []\n",
    "for i in range(1,10):\n",
    "    for j in range(1,10):\n",
    "        for k in range(1,10):\n",
    "            offer = f\"{i}-{j}-{k}\"\n",
    "            response = agentResponse(offer, threshold=0.65, exp_level=0.25)\n",
    "            if response.startswith('\"I think this offer could work.'):\n",
    "                count +=1\n",
    "                temp.append( calPayoff([int(n) for n in offer.split(\"-\")]) )\n",
    "                if calPayoff([int(n) for n in max_offer.split(\"-\")]) < calPayoff([int(n) for n in offer.split(\"-\")]):\n",
    "                    max_offer = offer\n",
    "                if calPayoff([int(n) for n in min_offer.split(\"-\")]) > calPayoff([int(n) for n in offer.split(\"-\")]):\n",
    "                    min_offer = offer\n",
    "print(count)\n",
    "print(max_offer, calPayoff([int(n) for n in max_offer.split(\"-\")]))\n",
    "print(min_offer)\n",
    "temp.sort()\n",
    "print(temp)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negotiation(OPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_to_run = CHATGPT\n",
    "\n",
    "temp_output = experiment(m_to_run, temperature=0.5, repeat=20)\n",
    "temp_output_pd = pd.DataFrame(temp_output)\n",
    "temp_output_pd.to_csv(m_to_run+'_results_updated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_to_run = FURBO\n",
    "\n",
    "temp_output = experiment(m_to_run, temperature=0.5, repeat=10)\n",
    "temp_output_pd = pd.DataFrame(temp_output)\n",
    "temp_output_pd.to_csv(m_to_run+'_results_0_9_updated.csv',index=False)\n",
    "\n",
    "temp_output = experiment(m_to_run, temperature=0.5, repeat=10)\n",
    "temp_output_pd = pd.DataFrame(temp_output)\n",
    "temp_output_pd.to_csv(m_to_run+'_results_10_19_updated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_to_run = SONNET\n",
    "\n",
    "#temp_output = experiment(m_to_run, temperature=0.5, repeat=4)\n",
    "#temp_output_pd = pd.DataFrame(temp_output)\n",
    "#temp_output_pd.to_csv(m_to_run+'_results_0_3.csv',index=False)\n",
    "\n",
    "#temp_output = experiment(m_to_run, temperature=0.5, repeat=4)\n",
    "#temp_output_pd = pd.DataFrame(temp_output)\n",
    "#temp_output_pd.to_csv(m_to_run+'_results_4_7.csv',index=False)\n",
    "\n",
    "#temp_output = experiment(m_to_run, temperature=0.5, repeat=4)\n",
    "#temp_output_pd = pd.DataFrame(temp_output)\n",
    "#temp_output_pd.to_csv(m_to_run+'_results_8_11.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=4)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_12_15.csv',index=False)\n",
    "\n",
    "temp_output = experiment(m_to_run, temperature=0.5, repeat=4)\n",
    "temp_output_pd = pd.DataFrame(temp_output)\n",
    "temp_output_pd.to_csv(m_to_run+'_results_16_19.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_to_run = OPUS\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_0_1.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_2_3.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_4_5.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_6_7.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_8_9.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_10_11.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_12_13.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_14_15.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_16_17.csv',index=False)\n",
    "\n",
    "# temp_output = experiment(m_to_run, temperature=0.5, repeat=2)\n",
    "# temp_output_pd = pd.DataFrame(temp_output)\n",
    "# temp_output_pd.to_csv(m_to_run+'_results_18_19.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
